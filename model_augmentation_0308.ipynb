{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fOrPhevoOPUoHTIYOqwVddjhhGRjP_v_","timestamp":1678252502193}],"toc_visible":true,"mount_file_id":"1pbEgkB4yYKAtPKUY3D5wA6mkq-MCPvkk","authorship_tag":"ABX9TyMorcSUXrZh3mCiTKWXzysv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 라이브러리 불러오기"],"metadata":{"id":"WgOpgLe0h7pg"}},{"cell_type":"code","source":["!pip install timm"],"metadata":{"id":"YHF3bJWr1RpZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679271657995,"user_tz":-540,"elapsed":6979,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"63ed2aaf-a64b-4852-9f79-f57ec63e67a0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.14.1+cu116)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.13.1+cu116)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.13.2 timm-0.6.12\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QBMjGyLGgyvP","executionInfo":{"status":"ok","timestamp":1679271717464,"user_tz":-540,"elapsed":5719,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"outputs":[],"source":["\n","# 사용 툴 : albumentation, tta\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from glob import glob\n","import pandas as pd\n","import numpy as np \n","from tqdm import tqdm\n","import cv2\n","\n","import os\n","import timm\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from sklearn.metrics import f1_score, accuracy_score\n","import time\n","\n","\n","device = torch.device('cuda')"]},{"cell_type":"markdown","source":["#### 시드 설정"],"metadata":{"id":"rQxThMSvIbt9"}},{"cell_type":"code","source":["def seed_all(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_all(42)"],"metadata":{"id":"PsiAYvUn90-a","executionInfo":{"status":"ok","timestamp":1679271721028,"user_tz":-540,"elapsed":3,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/DL_Project\")"],"metadata":{"id":"5V481GB6xHxn","executionInfo":{"status":"ok","timestamp":1679271721028,"user_tz":-540,"elapsed":2,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_png = sorted(glob('train/*.png'))\n","test_png = sorted(glob('test/*.png'))"],"metadata":{"id":"snNQR0Y8g2OS","executionInfo":{"status":"ok","timestamp":1679271760450,"user_tz":-540,"elapsed":39424,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["len(train_png), len(test_png)"],"metadata":{"id":"hy9ykBBB1g-A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679271760451,"user_tz":-540,"elapsed":7,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"593d759b-2dda-4af8-ca3f-34c8aa92eaea"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4277, 2154)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train_y = pd.read_csv(\"/content/drive/MyDrive/DL_Project/train_df.csv\")\n","\n","train_labels = train_y[\"label\"]\n","\n","label_unique = sorted(np.unique(train_labels))\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","train_labels = [label_unique[k] for k in train_labels]"],"metadata":{"id":"BWEKla_shQDy","executionInfo":{"status":"ok","timestamp":1679271786017,"user_tz":-540,"elapsed":1673,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["normalize = train_y['label'].value_counts(normalize=True)"],"metadata":{"id":"xVuq9Q-P8c0k","executionInfo":{"status":"ok","timestamp":1679239325792,"user_tz":-540,"elapsed":14,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["weight_ratio = 10 - normalize *100"],"metadata":{"id":"lW4IEUKI8ekE","executionInfo":{"status":"ok","timestamp":1679239325793,"user_tz":-540,"elapsed":14,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["weight_list_all = np.ones(88)\n","for key in weight_ratio.index:\n","    idx = label_unique[key]\n","    weight = weight_ratio[key]\n","    weight_list_all[idx] = weight\n","weight_list_all_tensor = torch.FloatTensor(weight_list_all).cuda()\n","print(weight_list_all_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hb2AfgTZ8fLM","executionInfo":{"status":"ok","timestamp":1679239330857,"user_tz":-540,"elapsed":5078,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"02398d7d-60ba-483b-9c46-9b9d0faf28c6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([9.7662, 9.7428, 9.7428, 5.1134, 9.8363, 9.8597, 9.8597, 9.8363, 9.8831,\n","        4.7627, 9.8597, 9.8831, 9.8831, 9.7194, 9.7428, 4.8796, 9.7428, 9.7194,\n","        9.7662, 9.7662, 9.7896, 3.4534, 9.7896, 9.7896, 9.7662, 9.8597, 9.8597,\n","        9.8597, 3.8274, 9.8597, 9.8597, 9.7896, 9.7896, 0.8581, 9.7896, 9.7896,\n","        9.7662, 9.7662, 9.7896, 9.7662, 4.2717, 9.7896, 9.6960, 9.7428, 9.7194,\n","        4.8562, 9.7194, 9.6960, 9.7896, 9.7428, 9.6960, 9.7662, 3.7573, 9.8831,\n","        9.7194, 2.5181, 9.7194, 9.7194, 9.6960, 9.7194, 9.7194, 9.7896, 9.7896,\n","        4.6224, 9.8130, 9.7896, 9.8130, 9.6493, 8.5971, 9.8831, 9.8831, 9.8831,\n","        5.0199, 9.8831, 9.9065, 9.8597, 4.2249, 9.8831, 9.8831, 9.7428, 9.7662,\n","        9.8130, 9.7896, 9.8130, 4.3886, 9.7896, 9.7896, 9.8130],\n","       device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["# image processing"],"metadata":{"id":"dx3TKA5w1374"}},{"cell_type":"code","source":["def img_load(path):\n","    img = cv2.imread(path)[:,:,::-1]\n","    img = cv2.resize(img, (384, 384))\n","    return img"],"metadata":{"id":"ht4fhxgKhSGW","executionInfo":{"status":"ok","timestamp":1679271790277,"user_tz":-540,"elapsed":513,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["- 현 모델은 BGR로 되어있지만 BGR2RGB를 써서 원래대로 되돌릴 수 있다\n","- 추천 모델 and 사이즈 : b0 : 224, b4 : 384, b6 : 512"],"metadata":{"id":"2RQ8E16YCC2m"}},{"cell_type":"code","source":["train_imgs = [img_load(m) for m in tqdm(train_png)] # train_imgs 다운로드\n","test_imgs = [img_load(n) for n in tqdm(test_png)] # test_imgs 다운로드"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECSAs80mhj_7","outputId":"e2d7044e-e786-4933-d72f-b53cdaa582ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4277/4277 [09:02<00:00,  7.89it/s]\n"," 89%|████████▉ | 1912/2154 [51:58<08:12,  2.04s/it]"]}]},{"cell_type":"markdown","source":["# Custom Dataset\n","> augmentation : argumentation 함수를 따로 만들지 않고 안에 넣어줬습니다.\n","> 수평, 수직 뒤집, 랜덤 회전, affine 변환을 썼습니다."],"metadata":{"id":"v7JvsyIbYG3d"}},{"cell_type":"code","source":["class Custom_dataset(Dataset):\n","    def __init__(self, img_paths, labels, mode='train'):\n","        self.img_paths = img_paths\n","        self.labels = labels\n","        self.mode=mode\n","    def __len__(self):\n","        return len(self.img_paths)\n","    def __getitem__(self, idx):\n","        img = self.img_paths[idx]\n","        if self.mode == 'train':\n","            train_transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n","                                     std = [0.181572, 0.174035, 0.163234]),\n","                transforms.RandomAffine((-45, 45)),\n","                transforms.RandomHorizontalFlip(p=0.5),\n","                transforms.RandomVerticalFlip(p=0.5),\n","                transforms.RandomRotation(degrees = (-90, 90)),\n","                transforms.RandomCrop(340)        \n","            ])\n","            img = train_transform(img)\n","        if self.mode == 'test':\n","            test_transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n","                                     std = [0.195055, 0.190053, 0.185323])\n","            ])\n","            img = test_transform(img)\n","\n","        \n","        label = self.labels[idx]\n","        return img, label\n","    \n","class Network(nn.Module):\n","    def __init__(self,mode = 'train'):\n","        super(Network, self).__init__()\n","        self.mode = mode\n","        if self.mode == 'train':\n","            self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n","        if self.mode == 'test':\n","            self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=88, drop_path_rate = 0)\n","        \n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"pYAAzX9Khqrw","executionInfo":{"status":"ok","timestamp":1679242162410,"user_tz":-540,"elapsed":13,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## score, data loader\n","이 파트는 데이콘의 기본 모델을 베이스로 구성했습니다."],"metadata":{"id":"sKDsGyPgdAau"}},{"cell_type":"code","source":["# 여기는 score를 계산하는 것으로 보입니다.\n","def score_function(real, pred):\n","  score = f1_score(real, pred, average=\"macro\")\n","  return score"],"metadata":{"id":"1tgTXLDJ2c6p","executionInfo":{"status":"ok","timestamp":1679242162410,"user_tz":-540,"elapsed":3,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# dataset : 전체 dataset 구성 dataloader : mini batch 만드는 역할할\n","batch_size = 32 # batch_size : 사진들을 몇 개 묶음으로 할 거냐\n","epochs = 60 # 학습 시도 횟수\n","\n","# 데이터 셋과 데이터 로더 부분\n","\n","# Train\n","train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train') # train 데이터셋 학습 모델델\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","\n","# Test\n","test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test') # test 데이터셋 학습 모델델\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"],"metadata":{"id":"wL6iwVRGhrQ3","executionInfo":{"status":"ok","timestamp":1679242165944,"user_tz":-540,"elapsed":3537,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# training"],"metadata":{"id":"fkCuA_mI264n"}},{"cell_type":"markdown","source":["train을 잘 짜야 잘 돌아갑니다잉"],"metadata":{"id":"uE6se6n33L_X"}},{"cell_type":"code","source":["def score_function(real, pred):\n","    score = f1_score(real, pred, average=\"macro\")\n","    return score # 모델 스코어\n","\n","model = Network().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","scaler = torch.cuda.amp.GradScaler() \n","\n","\n","\n","best=0\n","for epoch in range(epochs): # 학습 기본 설정 setting\n","    start=time.time()\n","    train_loss = 0\n","    train_pred=[]\n","    train_y=[]\n","    model.train()\n","    for batch in (train_loader):\n","        optimizer.zero_grad()   \n","        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n","        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n","        with torch.cuda.amp.autocast():\n","            pred = model(x)\n","        loss = criterion(pred, y)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        train_loss += loss.item()/len(train_loader)\n","        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n","        train_y += y.detach().cpu().numpy().tolist()\n","        \n","    \n","    train_f1 = score_function(train_y, train_pred)\n","\n","    TIME = time.time() - start\n","    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s') # 시간 확인 안내내\n","    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n","    if train_f1 > 0.99:\n","      model_path = \"/content/drive/MyDrive/open/model\"\n","      torch.save(model.state_dict(), f\"{train_f1}.pt\")"],"metadata":{"id":"kzUyfNKshwXm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679250279739,"user_tz":-540,"elapsed":8113800,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"8caa027f-a519-4406-8aab-b63548b46d5c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b4_ra2_320-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_ra2_320-7eb33cd5.pth\n"]},{"output_type":"stream","name":"stdout","text":["epoch : 1/50    time : 190s/9310s\n","TRAIN    loss : 0.95839    f1 : 0.25713\n","epoch : 2/50    time : 163s/7815s\n","TRAIN    loss : 0.44550    f1 : 0.44801\n","epoch : 3/50    time : 163s/7644s\n","TRAIN    loss : 0.33061    f1 : 0.57503\n","epoch : 4/50    time : 163s/7491s\n","TRAIN    loss : 0.26503    f1 : 0.67511\n","epoch : 5/50    time : 162s/7298s\n","TRAIN    loss : 0.18957    f1 : 0.73609\n","epoch : 6/50    time : 162s/7128s\n","TRAIN    loss : 0.17702    f1 : 0.76748\n","epoch : 7/50    time : 163s/7029s\n","TRAIN    loss : 0.14455    f1 : 0.81746\n","epoch : 8/50    time : 163s/6861s\n","TRAIN    loss : 0.14063    f1 : 0.83818\n","epoch : 9/50    time : 165s/6746s\n","TRAIN    loss : 0.12499    f1 : 0.85228\n","epoch : 10/50    time : 163s/6521s\n","TRAIN    loss : 0.11424    f1 : 0.86981\n","epoch : 11/50    time : 163s/6351s\n","TRAIN    loss : 0.09340    f1 : 0.88451\n","epoch : 12/50    time : 163s/6182s\n","TRAIN    loss : 0.07834    f1 : 0.90364\n","epoch : 13/50    time : 163s/6046s\n","TRAIN    loss : 0.08774    f1 : 0.88810\n","epoch : 14/50    time : 164s/5887s\n","TRAIN    loss : 0.11253    f1 : 0.88493\n","epoch : 15/50    time : 163s/5689s\n","TRAIN    loss : 0.07541    f1 : 0.91597\n","epoch : 16/50    time : 161s/5491s\n","TRAIN    loss : 0.06473    f1 : 0.92783\n","epoch : 17/50    time : 161s/5325s\n","TRAIN    loss : 0.07388    f1 : 0.92291\n","epoch : 18/50    time : 162s/5177s\n","TRAIN    loss : 0.07020    f1 : 0.90896\n","epoch : 19/50    time : 162s/5018s\n","TRAIN    loss : 0.04721    f1 : 0.94531\n","epoch : 20/50    time : 160s/4808s\n","TRAIN    loss : 0.06145    f1 : 0.93306\n","epoch : 21/50    time : 160s/4626s\n","TRAIN    loss : 0.05779    f1 : 0.93273\n","epoch : 22/50    time : 161s/4515s\n","TRAIN    loss : 0.06337    f1 : 0.93402\n","epoch : 23/50    time : 160s/4310s\n","TRAIN    loss : 0.06230    f1 : 0.93920\n","epoch : 24/50    time : 159s/4127s\n","TRAIN    loss : 0.05237    f1 : 0.94613\n","epoch : 25/50    time : 159s/3982s\n","TRAIN    loss : 0.06774    f1 : 0.93996\n","epoch : 26/50    time : 159s/3816s\n","TRAIN    loss : 0.05114    f1 : 0.95001\n","epoch : 27/50    time : 159s/3661s\n","TRAIN    loss : 0.04566    f1 : 0.95906\n","epoch : 28/50    time : 161s/3543s\n","TRAIN    loss : 0.04185    f1 : 0.95093\n","epoch : 29/50    time : 162s/3394s\n","TRAIN    loss : 0.06843    f1 : 0.95007\n","epoch : 30/50    time : 163s/3266s\n","TRAIN    loss : 0.05726    f1 : 0.93761\n","epoch : 31/50    time : 162s/3080s\n","TRAIN    loss : 0.04806    f1 : 0.95203\n","epoch : 32/50    time : 163s/2941s\n","TRAIN    loss : 0.03652    f1 : 0.95635\n","epoch : 33/50    time : 162s/2748s\n","TRAIN    loss : 0.03423    f1 : 0.96464\n","epoch : 34/50    time : 161s/2576s\n","TRAIN    loss : 0.02117    f1 : 0.97095\n","epoch : 35/50    time : 161s/2415s\n","TRAIN    loss : 0.02825    f1 : 0.96887\n","epoch : 36/50    time : 161s/2254s\n","TRAIN    loss : 0.03539    f1 : 0.94863\n","epoch : 37/50    time : 162s/2107s\n","TRAIN    loss : 0.04925    f1 : 0.95427\n","epoch : 38/50    time : 162s/1939s\n","TRAIN    loss : 0.04090    f1 : 0.94982\n","epoch : 39/50    time : 161s/1775s\n","TRAIN    loss : 0.04406    f1 : 0.94945\n","epoch : 40/50    time : 161s/1614s\n","TRAIN    loss : 0.03738    f1 : 0.96372\n","epoch : 41/50    time : 161s/1451s\n","TRAIN    loss : 0.04385    f1 : 0.95215\n","epoch : 42/50    time : 161s/1290s\n","TRAIN    loss : 0.05758    f1 : 0.95038\n","epoch : 43/50    time : 162s/1131s\n","TRAIN    loss : 0.03807    f1 : 0.95764\n","epoch : 44/50    time : 163s/977s\n","TRAIN    loss : 0.03431    f1 : 0.96173\n","epoch : 45/50    time : 161s/805s\n","TRAIN    loss : 0.04668    f1 : 0.94356\n","epoch : 46/50    time : 162s/646s\n","TRAIN    loss : 0.03782    f1 : 0.94581\n","epoch : 47/50    time : 162s/485s\n","TRAIN    loss : 0.04891    f1 : 0.95411\n","epoch : 48/50    time : 161s/321s\n","TRAIN    loss : 0.02482    f1 : 0.96198\n","epoch : 49/50    time : 161s/161s\n","TRAIN    loss : 0.03939    f1 : 0.95773\n","epoch : 50/50    time : 161s/0s\n","TRAIN    loss : 0.01764    f1 : 0.97928\n"]}]},{"cell_type":"markdown","source":["# 모델 추론\n","- 이건 말 그대로 모델의 학습이 끝난 직후, 어떤 방식으로 모델의 정확도를 높일 수 있을 지를 생각하는 코드입니다. "],"metadata":{"id":"8n2uJWRbjTzX"}},{"cell_type":"code","source":["model.eval()\n","f_pred = [] \n","\n","with torch.no_grad():\n","    for batch in (test_loader):\n","        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n","        with torch.cuda.amp.autocast():\n","            pred = model(x)\n","        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"],"metadata":{"id":"P392eEfLjPGA","executionInfo":{"status":"ok","timestamp":1679250298665,"user_tz":-540,"elapsed":18603,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["label_decoder = {val:key for key, val in label_unique.items()} \n","\n","f_result = [label_decoder[result] for result in f_pred]"],"metadata":{"id":"TOVkXR0Zjb_O","executionInfo":{"status":"ok","timestamp":1679250298666,"user_tz":-540,"elapsed":18,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# 결과창"],"metadata":{"id":"LRRRVihU3u5m"}},{"cell_type":"code","source":["submission = pd.read_csv(\"/content/drive/MyDrive/DL_Project/sample_submission.csv\") # 데이터 제출출\n","\n","submission[\"label\"] = f_result\n","\n","submission"],"metadata":{"id":"lRMRKSu9jck2","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1679250298666,"user_tz":-540,"elapsed":17,"user":{"displayName":"정영운","userId":"08661002276326861946"}},"outputId":"70ad8325-cc18-4443-fe1c-65bded111874"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      index             label\n","0         0   tile-glue_strip\n","1         1         grid-good\n","2         2   transistor-good\n","3         3  tile-gray_stroke\n","4         4         tile-good\n","...     ...               ...\n","2149   2149  tile-gray_stroke\n","2150   2150        screw-good\n","2151   2151         grid-good\n","2152   2152        cable-good\n","2153   2153       zipper-good\n","\n","[2154 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3d0df3b9-8e24-4dd2-8b73-70d50323c180\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>tile-glue_strip</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>grid-good</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>transistor-good</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>tile-gray_stroke</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>tile-good</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2149</th>\n","      <td>2149</td>\n","      <td>tile-gray_stroke</td>\n","    </tr>\n","    <tr>\n","      <th>2150</th>\n","      <td>2150</td>\n","      <td>screw-good</td>\n","    </tr>\n","    <tr>\n","      <th>2151</th>\n","      <td>2151</td>\n","      <td>grid-good</td>\n","    </tr>\n","    <tr>\n","      <th>2152</th>\n","      <td>2152</td>\n","      <td>cable-good</td>\n","    </tr>\n","    <tr>\n","      <th>2153</th>\n","      <td>2153</td>\n","      <td>zipper-good</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2154 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d0df3b9-8e24-4dd2-8b73-70d50323c180')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3d0df3b9-8e24-4dd2-8b73-70d50323c180 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3d0df3b9-8e24-4dd2-8b73-70d50323c180');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["submission[['index','label']].to_csv(\"/content/drive/MyDrive/DL_Project/sample_submission.csv\", index=False)"],"metadata":{"id":"pwC4BTkQ73-o","executionInfo":{"status":"ok","timestamp":1679250298667,"user_tz":-540,"elapsed":6,"user":{"displayName":"정영운","userId":"08661002276326861946"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## 앙상블 기법\n","- 여러분이 아시는 그 앙상블로, 파라미터나 epoch, batch, resize 등 다양한 기법으로 만들어진 모델 중 \n","- 괜찮은 것들을 찾아 앙상블하는 것입니다.\n","- 근데 모델이 많이 있어야 하네요? 이건 결과를 낸 후 시도해봅시다\n","- 최종적으로 실행하지 못하였습니다. 이 부분은 초반에 헤맨 부분이 많아서 개인적으로 아쉽네요."],"metadata":{"id":"d9nvDEF-3cP-"}},{"cell_type":"code","source":[],"metadata":{"id":"qXzC4NDlJJ7t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# train 코드 (reference)\n","- 데이콘의 다른 예시들이 코드를 실험하는 데 큰 도움이 되었습니다."],"metadata":{"id":"xdmLcGtgO2tO"}},{"cell_type":"code","source":["# 시도 횟수\n","n_epochs = 100\n","valid_loss_min = np.inf # 100보다 작을 시 멈춤\n","\n","# keep track of training and validation loss\n","train_loss = torch.zeros(n_epochs)\n","valid_loss = torch.zeros(n_epochs)\n","\n","train_F1 = torch.zeros(n_epochs)\n","valid_F1 = torch.zeros(n_epochs)\n","model.to(device)\n","\n","for e in range(0, n_epochs):\n","\n","   \n","    ###################\n","    # 모델 학습       #\n","    ###################\n","    model.train()\n","    for data, labels in tqdm(train_dataloader):\n","        # move tensors to GPU if CUDA is available\n","        data, labels = data.to(device), labels.to(device)\n","        # 순전파 :compute predicted outputs by passing inputs to the model\n","        logits = model(data)\n","        # 배치의 손실율 계산\n","        loss = criterion(logits, labels)\n","\n","        optimizer.zero_grad()\n","        # 역전파 : compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # 싱글 옵티미제이션(adam)\n","        optimizer.step()\n","        # 학습 손실율 업데이트\n","        train_loss[e] += loss.item()\n","        # 학습 스코어 계산산\n","        logits=logits.argmax(1).detach().cpu().numpy().tolist()\n","        labels=labels.detach().cpu().numpy().tolist()\n","\n","        train_F1[e] += score_function(labels,logits)\n","\n","    train_loss[e] /= len(train_dataloader)\n","    train_F1[e] /= len(train_dataloader)\n","        \n","        \n","    ######################    \n","    # 검증 모델          #\n","    ######################\n","    with torch.no_grad(): \n","        model.eval()\n","        for data, labels in tqdm(valid_dataloader):\n","            # move tensors to GPU if CUDA is available\n","            data, labels = data.to(device), labels.to(device)\n","            # 순전파: compute predicted outputs by passing inputs to the model\n","            logits = model(data)\n","            # 배치 손실율 계산\n","            loss = criterion(logits, labels)\n","            # 평균 검증 손실율 \n","            valid_loss[e] += loss.item()\n","            # update training score\n","            logits=logits.argmax(1).detach().cpu().numpy().tolist()\n","            labels=labels.detach().cpu().numpy().tolist()\n","            valid_F1[e] += score_function(labels,logits)\n","            \n","    \n","    # 평균 손실율 계산산\n","    valid_loss[e] /= len(valid_dataloader)\n","    valid_F1[e] /= len(valid_dataloader)\n","    \n","    scheduler.step(valid_loss[e])    \n","    # 학습/검증 결과 산출 표시(loss)\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        e, train_loss[e], valid_loss[e]))\n","    \n","    # 학습/검증 결과 산출 표시(정확도도)\n","    print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n","        e, train_F1[e], valid_F1[e]))\n","    \n","    # 검증 손실율이 줄어들었을 때 모델 저장장\n","    if valid_loss[e] <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss[e]))\n","        torch.save(model.state_dict(), 'swin_tiny_patch4_window7_224.pt')\n","        valid_loss_min = valid_loss[e]"],"metadata":{"id":"w9m1iBf8O2Gg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 증강 alpha 테스트"],"metadata":{"id":"Z-e8dNkaOBHr"}},{"cell_type":"markdown","source":["- albumentation과 transform 고려\n","- 최종적으로는 transform을 사용(별 이유는 없음)"],"metadata":{"id":"cJJjDzMiaOCt"}},{"cell_type":"code","source":["# 하는 방법\n","import albumentations\n","import albumentations.pytorch\n","\n","aug = albumentations.Compose([\n","      albumentations.Resize(224, 224),\n","      albumentations.HorizontalFlip(), #수평 뒤집기기 \n","      albumentations.VerticalFlip(), #수직 뒤집기\n","      albumentations.OneOf([\n","                          albumentations.Rotate(), # 돌리기기\n","                          albumentations.ShiftScaleRotate()\n"," \n","      ], p=1),\n","      albumentations.augmentations.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), #정규화화\n","      albumentations.pytorch.transforms.ToTensorV2(p=1.0)\n","      ])\n","aug2 = albumentations.Compose([\n","      albumentations.Resize(224, 224),\n","      albumentations.Rotate(), # 돌리기기\n","      albumentations.augmentations.transforms.Normalize(mean=(0.5,), std=(0.5,), p=1.0),\n","      albumentations.pytorch.transforms.ToTensorV2(p=1.0)\n","      ])"],"metadata":{"id":"IgYuMjp3OAao"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 아쉬운 점\n","- train 정확도가 99%를 찍지 못해서 원하는 모델을 추출하지 못한게 아쉬움\n","- 모델 앙상블 기법을 제대로 시도하지 못한 것도 아쉬움\n","- 512 size와 b6~b7 모델을 시험하거나 다양한 변수값을 조작하지 못하였음 "],"metadata":{"id":"SDcYgxkQa3Xe"}},{"cell_type":"markdown","source":["# 결론\n","- 우리가 해야 될 것은 뭘까요?\n","    - 1. 이미지 전처리(기법 활용)를 모델에 맞춰서 잘 하는 것\n","    - 2. effiecientb0~b7의 모델 중 좋은 모델을 찾아서\n","    - 3. training & validation 코드를 잘 짜고 (전체적인 과정 이해하면 더 좋아요!)\n","    - 4. 결과값이 나오면 어떻게 parameter를 만질지 고민, image-argumentation, ensemble, 5-fold 적극 활용!\n","    - 5. 최대한 다양한 모델을 만들어 보고 최적의 결과 찾기!"],"metadata":{"id":"MLAobuz6QlYk"}},{"cell_type":"markdown","source":["## 후일담\n","\n","- 나중엔 코드를 정렬해서 전역 파라미터를 한 자리에서 설정할 수 있게 코드를 짜 보고 싶음 (밑 코드 참조)\n","\n"],"metadata":{"id":"pMWpvnix1ndn"}},{"cell_type":"code","source":["config = { # 전역 파라미터 변수 설정정\n","    # Model parameters\n","    'model': 'efficientnet_b0',\n","    'batch_size': 32,\n","    'pretrain': True,\n","    \n","    # Optimizer parameters\n","    'optimizer': 'AdamW',\n","    'lr': 2e-4,\n","    'lr_t': 15,\n","    'lr_scheduler': 'CosineAnnealingWarmUpRestarts',\n","    'gamma': 0.524,\n","    'loss_function': 'CE_with_Lb',\n","    'patience': 10,\n","    'weight_decay': 0.002157,\n","    'label_smoothing': 0.8283,\n","    \n","    # Training parameters\n","    'epochs': 200,\n","    'n_fold': 5,\n","    'num_workers': 16,\n","    'text': \"A\",\n","    'device': '0,1,2,3'\n","    }"],"metadata":{"id":"JomYt9wE7W4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_args_parser(): # 기본 인자값 부여로 보임임\n","    parser = argparse.ArgumentParser('PyTorch Inference', add_help=False)\n","\n","    # Inference parameters\n","    parser.add_argument('--model_save_name', nargs='+', default='load_model', type=str)\n","    parser.add_argument('--model', default='efficientnet_b7', type=str)\n","    parser.add_argument('--batch_size', default=32, type=int)\n","    parser.add_argument('--pretrain', default=True, type=str2bool)\n","    parser.add_argument('--n_fold', default=5, type=int)\n","    parser.add_argument('--num_workers', default=16, type=int)\n","    parser.add_argument('--device', default='0,1,2,3', type=str)\n","    parser.add_argument('--tta', default=True, type=str2bool)\n","    parser.add_argument('--save_name', default='default', type=str)"],"metadata":{"id":"nTJcI5pW7BLs"},"execution_count":null,"outputs":[]}]}